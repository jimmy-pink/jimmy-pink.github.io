
## 知识图
```
人工智能（AI）
│
├──▸ 机器学习（ML）
│    ├── 监督/无监督/强化学习
│    ├── 模型：XGBoost, LightGBM, CatBoost
│    └── 框架：scikit-learn, PyTorch, TensorFlow, HuggingFace
│
├──▸ 深度学习（DL）
│    ├── 神经网络、CNN、RNN、Transformer
│    ├── 框架：PyTorch, TensorFlow, Keras, JAX
│    └── 微调工具：LoRA, PEFT, DeepSpeed, BitsAndBytes
│
├──▸ 自然语言处理（NLP）
│    ├── 语言模型：BERT, GPT, LLaMA, Mistral
│    ├── Embedding：SentenceTransformers, OpenAI Embedding
│    ├── 向量化检索：BM25, dense embedding
│    └── 文本处理：spaCy, NLTK, TextBlob
│
├──▸ 多模态处理（Vision+Text, Audio）
│    ├── 图像识别：YOLOv8, CLIP, Segment Anything
│    ├── 音频分析：Whisper, Wav2Vec2
│    ├── 视频：InternVideo, SloMo
│    └── 多模态模型：Gemini, Florence, OpenFlamingo
│
├──▸ 检索增强生成（RAG）
│    ├── 向量数据库：FAISS, Weaviate, Qdrant, pgvector
│    ├── 检索模型：ColBERT, DenseRetriever
│    ├── 工具框架：LangChain, LlamaIndex, Haystack
│    └── 预处理：Chunking, Text Splitter, Metadata Tagging
│
├──▸ 智能体系统（AI Agents）
│    ├── 基础框架：LangGraph, AutoGen, CrewAI, AgentLite
│    ├── 能力集成：Tool calling, Function calling
│    ├── 调度规划：ReAct, Plan&Execute, SWIFT
│    └── 模拟环境：OpenSim, BabyAGI, CAMEL
│
├──▸ 向量表示与信息检索（IR）
│    ├── 向量存储：PostgreSQL+pgvector, Chroma, Redis-Vec
│    ├── 索引优化：IVF, HNSW, PQ, ScaNN
│    ├── 混合检索：BM25 + Dense + rerank (Cohere, ColBERT)
│    └── 召回+排序：retriever + reranker 架构
│
├──▸ 数据工程（Data Engineering）
│    ├── 数据清洗：pandas, Polars, Great Expectations
│    ├── 数据处理流：Airflow, Dagster, Prefect, Metaflow
│    ├── 数据标注：Label Studio, Doccano, Prodigy
│    └── 数据仓库：DuckDB, Delta Lake, BigQuery
│
├──▸ 系统部署与服务（AI Infra）
│    ├── API 服务：FastAPI, Flask, Gradio, Streamlit
│    ├── 微服务：Docker, Kubernetes, Ray, Triton
│    ├── 模型部署：vLLM, TGI, OpenLLM, BentoML
│    ├── 加速工具：ONNX, TensorRT, DeepSpeed, FlashAttention
│    └── 前端集成：Next.js, Vue3, TailwindCSS
│
├──▸ 模型监控与反馈（AI Ops）
│    ├── 模型监控：WhyLabs, Prometheus + Grafana
│    ├── 日志 & 分析：MLflow, WandB, OpenTelemetry
│    ├── LLM 回答评估：Ragas, EvalLM, Promptfoo
│    └── A/B Test, Human Feedback, RLHF 工具链
│
└──▸ 安全性与伦理（AI Safety）
     ├── 审查检测：OpenAI Guardrails, Rebuff, ReACT Guard
     ├── 模型对齐：RLHF, DPO, Constitutional AI
     ├── 数据脱敏：PII Masking, DeID 工具
     └── 值观调优：Anthropic Constitutional Training, OpenChat
```

## 学习顺序 
**建议的学习顺序和内容：**

#### 阶段一：基础巩固与AI入门 (Leverage & Refresh)
1. **数学基础复习与深化 (至关重要)：**
    - **线性代数：** 向量、矩阵运算、特征值/特征向量、SVD等。理解它们在数据表示和算法中的作用。
    - **微积分：** 导数、偏导数、梯度、链式法则等。理解它们在模型优化（梯度下降）中的核心地位。
    - **概率论与统计学：** 概率分布、条件概率、贝叶斯定理、假设检验、最大似然估计(MLE)、最大后验概率(MAP)等。理解它们是构建和评估模型的基础。
    - **重点：** 不要仅仅停留在公式层面，要努力理解这些数学概念在AI算法中的直观意义和应用。你的编程背景可以帮助你通过代码实现来加深理解。
2. **Python及AI生态核心库掌握：**
    - **Python精进：** 即使你熟悉其他语言，Python也是AI领域的事实标准。要达到熟练掌握的程度。
    - **NumPy：** 高效的数值计算，特别是多维数组操作。
    - **Pandas：** 数据处理和分析的利器，用于数据清洗、转换、探索。
    - **Matplotlib & Seaborn：** 数据可视化，用于理解数据和展示模型结果。
    - **Scikit-learn：** 机器学习基础库，包含大量经典算法、数据预处理工具、模型评估方法。这是你实践传统机器学习算法的主要阵地。
    - **Git & 环境管理：** (你可能已经很熟悉) 熟练使用Git进行版本控制，以及conda/venv等进行环境隔离。

#### 阶段二：核心机器学习理论与实践 (Core ML)
1. **机器学习基础概念：**
    - 监督学习、无监督学习、强化学习的定义和区别。
    - 特征工程：特征提取、选择、构造的重要性。
    - 模型评估与选择：训练集/验证集/测试集、交叉验证、欠拟合与过拟合、偏差与方差。
    - 常用评估指标：准确率、精确率、召回率、F1分数、AUC、RMSE、MAE等，理解它们的适用场景。
2. **经典机器学习算法学习与实践：**
    - **监督学习：**
        * 线性回归、逻辑回归 (理解基础模型和优化方法)
        * 支持向量机 (SVM) (理解间隔最大化)
        * 决策树、随机森林、梯度提升树 (GBDT, XGBoost, LightGBM) (理解集成学习思想，这些在结构化数据上依然非常强大)
    - **无监督学习：**
        * 聚类算法 (K-Means, DBSCAN)
        * 降维算法 (PCA)
    - **重点：** 对每个算法，不仅要会调用`sklearn`的API，还要理解其基本原理、假设、优缺点和适用场景。尝试手动实现简单的版本，加深理解。用真实或Kaggle数据集进行练习。

#### 阶段三：深度学习入门与实践 (Deep Learning)
1. **神经网络基础：**
    - 感知机、多层感知机 (MLP)。
    - 激活函数 (Sigmoid, Tanh, ReLU及其变种)。
    - 损失函数 (MSE, Cross-Entropy等)。
    - 反向传播算法和梯度下降优化器 (SGD, Adam等)。
2. **深度学习框架掌握 (至少精通一个)：**
    - **PyTorch** 或 **TensorFlow/Keras**。建议先深入学习其中一个（目前PyTorch在研究领域和灵活性上更受欢迎，TensorFlow在工业部署上历史更久），另一个了解即可。
    - 学习框架的基本操作、模型搭建、训练、评估流程。
3. **主流深度学习模型：**
    - **卷积神经网络 (CNN)：** 理解卷积、池化操作，掌握用于图像识别、目标检测等任务的基本CNN架构 (LeNet, AlexNet, VGG, ResNet等)。
    - **循环神经网络 (RNN)：** 理解其处理序列数据的能力和梯度消失/爆炸问题。
    - **LSTM / GRU：** 理解它们如何缓解RNN的长期依赖问题。
    - **(重要) Transformers：** 理解自注意力机制 (Self-Attention)，它是当前NLP领域的基石，并在CV等领域广泛应用 (如BERT, GPT, ViT)。
4. **实践：** 使用框架实现上述模型，并在标准数据集（如MNIST, CIFAR-10, IMDB等）上进行训练和评估。

#### 阶段四：专业方向深入与前沿探索 (Specialization & Advanced)
1. **选择细分领域：** 根据你的兴趣和就业市场需求，选择1-2个方向深入学习。
    - **自然语言处理 (NLP)：** 文本表示 (Word2Vec, GloVe, FastText)、序列标注、文本分类、机器翻译、问答系统、语言模型 (BERT, GPT系列)。
    - **计算机视觉 (CV)：** 图像分类、目标检测 (YOLO, Faster R-CNN)、图像分割、生成对抗网络 (GANs)、图像生成。
    - **强化学习 (RL)：** Q-Learning, Deep Q-Networks (DQN), Policy Gradients。
    - **推荐系统 (RecSys)：** 协同过滤、基于内容的推荐、深度学习推荐模型。
    - **机器学习运维 (MLOps)：** (非常适合有工程背景的你！) 模型部署、监控、自动化流水线 (CI/CD for ML)、模型版本管理、数据漂移检测。了解Docker, Kubernetes, CI/CD工具, 以及云平台 (AWS SageMaker, Google AI Platform, Azure ML) 的ML服务。
    - **数据科学/分析：** 如果你对从数据中提取洞见更感兴趣，可以深入统计建模、因果推断、A/B测试等。
2. **学习进阶模型与技术：** 阅读相关领域的经典论文和最新研究进展 (arXiv是个好地方)。
3. **参与更复杂的项目：** 尝试复现论文或参与Kaggle竞赛等，构建能体现你能力的代表性项目。

#### 贯穿始终
+ **项目驱动：** 学习过程中不断将理论知识应用于实际项目。构建个人作品集 (Portfolio) 至关重要，最好能部署上线展示。
+ **代码能力：** 保持高质量的编码习惯，注重代码的可读性、可维护性和效率。
+ **系统思维：** 思考AI模型如何集成到更大的软件系统中，考虑性能、扩展性、可靠性。MLOps尤其需要这种思维。
+ **持续学习：** AI领域发展极快，要养成阅读论文、技术博客、参加线上/线下技术交流的习惯。
+ **沟通与协作：** (软技能) 能够清晰地解释复杂的AI概念和模型结果给不同背景的人。





## 知识高亮

### 知识着色
知识库中部分重要或特别 知识将做如下背景着色：

 <font style="background-color:tomato; color:black"># 红底色tomato，Highlight章节概念、总结，需要理解和熟记。</font> 

<font style="background-color:yellow; color: black"># 黄色底色 yellow，Highlight一些重要的基本常识（CommonSense），往往是理解章节要义的前提。</font>

<font style="background-color:orange; color:black"># 橙色底色 orange，比较重要的拓展知识，一般也需要牢记。</font>

<font style="background-color:skyblue;color:black"># 蓝色底色 skyblue，是为了Highlight一些重要的定义（Definition）。</font>

<font style="background-color:lightgreen; color:black"># 绿色底色 lightgreen，Highlight一个有助于理解概念、知识点的通俗解释或补充说明</font>

<font style="color:grey;"># 灰色字体色，无关紧要，可忽略</font>

<font style="background-color:honeydew;"># 不是特别难理解的强调知识</font>

## 知识版权说明
<font style="background-color:yellow; color: black">我们不生产知识，我们只是知识的搬运工。</font>

本知识库只负责整理知识，将 AI 相关知识经过 GPT 解释和作者学习吸收后，再理解归纳出来的产物。知识版权最终归属于原作者 （参看下方知识引用），大多数知识都会标注知识来源。

<font style="background-color:tomato; color:black">本知识库仅供 AI 爱好者特别是非本专业的 AI 小白入门 交流学习之用。</font>

