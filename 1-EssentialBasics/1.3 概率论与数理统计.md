<h1 style=" text-align: center; font-size: 3em; font-family: 'Georgia', serif; color: #2c3e50; margin: 0.5em 0; padding: 10px 0; border-top: 4px solid #3498db; border-bottom: 4px solid #3498db; text-transform: uppercase; letter-spacing: 3px;"> 概率论与数理统计</h1>

[看见统计： 基础概率论](https://seeing-theory.brown.edu/basic-probability/cn.html) 概率论重要知识的统计可视化，建议玩一玩。

```text
概率论与数理统计核心知识点
├── 1. 随机事件与概率
│   ├── 1.1 随机试验与样本空间
│   ├── 1.2 事件的运算（并、交、补）
│   ├── 1.3 概率的定义（古典、几何、频率）
│   ├── 1.4 概率的基本性质
│   ├── 1.5 条件概率与乘法公式
│   └── 1.6 全概率公式与贝叶斯公式
├── 2. 随机变量及其分布
│   ├── 2.1 随机变量概念（离散、连续）
│   ├── 2.2 分布列、分布函数
│   ├── 2.3 常见离散分布
│   │   ├── 2.3.1 二项分布 B(n,p)
│   │   ├── 2.3.2 泊松分布 P(λ)
│   ├── 2.4 常见连续分布
│   │   ├── 2.4.1 均匀分布 U(a,b)
│   │   ├── 2.4.2 正态分布 N(μ,σ²)
│   │   ├── 2.4.3 指数分布
│   └── 2.5 多维随机变量（联合分布、边缘分布、条件分布）
├── 3. 随机变量的数字特征
│   ├── 3.1 数学期望
│   ├── 3.2 方差与标准差
│   ├── 3.3 协方差与相关系数
│   ├── 3.4 常用不等式
│   │   ├── 3.4.1 切比雪夫不等式
│   │   └── 3.4.2 Jensen不等式
├── 4. 大数定律与中心极限定理
│   ├── 4.1 大数定律（弱大数、强大数）
│   └── 4.2 中心极限定理（正态近似）
├── 5. 数理统计基础
│   ├── 5.1 样本与总体
│   ├── 5.2 样本统计量（样本均值、样本方差）
│   ├── 5.3 参数估计
│   │   ├── 5.3.1 点估计（无偏性、有效性、一致性）
│   │   ├── 5.3.2 区间估计
│   └── 5.4 假设检验
│       ├── 5.4.1 单侧检验与双侧检验
│       ├── 5.4.2 常见检验（t检验、χ²检验、F检验）
│       └── 5.4.3 第一类错误与第二类错误
├── 6. 重要分布
│   ├── 6.1 t分布
│   ├── 6.2 卡方分布（χ²）
│   └── 6.3 F分布
└── 7. 回归分析基础（选学）
    ├── 7.1 一元线性回归
    ├── 7.2 最小二乘法
    └── 7.3 多元回归概念
```


## 随机事件与概率
### 随机事件

#### 随机现象
- 定义：在相同条件下进行试验，每次结果不确定，但可能的结果事先知道。
	- 无限多 但可列举清楚，是随机现象。如飞镖打靶的靶点
	- 如果连可能结果事先都无法知识，不属于经典概率论讨论的内容。如向太空中投掷飞镖

#### 样本空间
- 定义：进行一次随机试验，所有可能结果组成的集全成为样本空间，通常记作$\Omega$
	- 可以是无穷个元素组成的集合

#### 事件
- 样本空间的一个子集
	- 比如，你关心投骰子的点大，那[4,5,6]**子集就是事件**
- 分类：
	- 必然事件：结果一定发生 P(Ω) = 1
	- 不可能事件：永远不会发生 P(∅) = 0
	- **互斥事件 (Mutually Exclusive Events)** 
		- **🌰:** 掷骰子时，“掷出 3 点”（A={3}）和“掷出 5 点”（B={5}）是互斥事件
	- **对立事件 (Complementary Events)**
		- 事件 E 和它的补集 E'  (E' 是指所有不属于 E 的基本事件的集合)
		- **🌰:** 掷骰子时，如果事件 E 是“掷出偶数”（E = {2, 4, 6}），那么它的对立事件 E' 就是“掷出奇数”（E' = {1, 3, 5}）。
	- **限定事件 (Defined Event)**
		- 样本空间的任意非空真子集（既不是 Ω 也不是 ∅）
		- **🌰:** 掷骰子时，“掷出小于 3 的点数”（E = {1, 2}）就是一个限定事件。

#### 事件的运算
- 定义： 给事件$A, B \subseteq \Omega$, 可以做如下运算
	- 并事件$A \cup B$：A或B至少发生一个
	- 交事件 $A \cap B$：A和B同时发生
	- 补事件$A{\prime}$ ：A没有发生

### 概率

#### 古典概型 (classical probability model)

- 定义： 如果一个试验有有限个可能结果，且每个结果发生的可能性相同称为古典概型
	- **有限结果**
	- **等可能**

####  **概率的公理化定义** (Kolmogorov Axiomatic Definition)

- 定义：概率是定义在样本空间上的函数P，满足：
	1. 非负性：$P(A) \geq 0$，对所有事件A。
	2. 规范性：$P(\Omega) = 1$ 。 一定发生的事概率是1
	3. 可列可加性：若$A_1, A_2, \ldots$两两互不干扰的事件，概率可以直接加起起来，公式：    $$P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)$$
#### 概率的基本性质
- **互斥事件的概率加法**：如果A和B互斥（不能同时发生），则
    $$P(A \cup B) = P(A) + P(B)$$
    
- **一般加法公式**（可能有交集，有交集的事件，要减去重复算的部分）：
    
    $$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$
    
- **补集公式**：
    
    $$P(A{\prime}) = 1 - P(A)$$
    
- **单调性**：$$\text{如果}A \subseteq B \text{，则} P(A) \leq P(B)$$

#### 条件概率与乘法公式
- 定义： 设 A、B 是两个事件，且 $P(B) > 0$，则事件 **在 B 发生的条件下，A 发生的概率** 叫做条件概率，记为：$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$
- 核心思想： 事件B确定发生时，事件A发生的可能性。如：下雨了，行人带伞的概率就是条件概率。
- 乘法公式：$$P(A \cap B) = P(B) \cdot P(A|B)$$

#### 全概率公式
- 定义：若事件 $B_1, B_2, …, B_n$ 是一个**完备事件组**（两两互不重叠，且其并为全集），且 A 是某个事件，则：$$P(A) = \sum_{i=1}^{n} P(B_i) \cdot P(A|B_i)$$
	- 如何一个事件A可以通过不同原因发生，那么A的总体概率如上公式。
#### 贝叶斯公式
- 想反向推到某个原因发生的概率时，贝叶斯公式：$$P(B_i | A) = \frac{P(B_i) \cdot P(A|B_i)}{\sum_{j=1}^{n} P(B_j) \cdot P(A|B_j)}$$
- 🌰：你已经知道某人咳嗽了（A 发生），你想知道他是因为流感（B₁）还是新冠（B₂）？
	- 用贝叶斯公式把每个原因出现的可能性重新计算一遍！

## 随机变量及其分布

### 随机变量

#### 定义
- 一个从样本空间到实数的函数，即：

$$X: \Omega \to \mathbb{R}$$

- 它把每个实验结果（样本点）映射为一个实数。
- 🧠：随机变量不是“变量”，而是**变量值和事件的桥梁**。
- 🌰：抛一次骰子，结果可能是 {1,2,3,4,5,6}，我们可以定义随机变量 X 为“骰子点数”，它会对应地取这些数值。
#### 离散与连续
- 离散随机变量：可数个数
- 连续随机变量：无穷不可数(区间内任意值)

#### 分布列 **（Distributions of Discrete Variables）**
设随机变量 X 取值 $x_1, x_2, …$，

定义：
$P(X = x_i) = p_i$

所有这些 (x_i, p_i) 构成 **分布列**，满足：

$\sum p_i = 1$

#### 分布函数

对任意随机变量 X，定义其分布函数：

$$F(x) = P(X \leq x)$$

  

对于离散变量，分布函数是“阶梯形”，

对于连续变量，分布函数是“光滑曲线”，且：

- 单调不减
    
$$\lim_{x \to -\infty} F(x) = 0，\lim_{x \to \infty} F(x) = 1$$

### 常见离散分布

#### 📌 二项分布
记作：$B(n, p)$

**定义：**

进行 n 次独立重复试验，每次成功概率为 p，随机变量 X 表示成功的次数。
  

$$P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}$$

**期望与方差：**

$$E(X) = np,\quad D(X) = np(1-p)$$

- 🔧 应用：重复 n 次实验（如投硬币、抽奖），关心成功（或失败）的次数。  
- ⚠️ **特点：**
    
    - 成功失败只有两种可能（“0-1 分布”的重复）
        
    - 有界取值：$X \in \{0,1,…,n\}$
        
    - 对称性：当 p = 0.5 时图像对称
    
#### 📌 泊松分布 (Poisson distribution)
记作：$P(\lambda)$
  
**定义：**

单位时间/空间内事件发生的次数（符合平均发生率 $\lambda$）：

$$P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!},\quad k = 0,1,2,…$$

  

**期望与方差：**

$$E(X) = D(X) = \lambda$$

- **应用：** 单位时间/空间内事件发生次数,如网络请求数、电话进线数、事故发生次数等。
- ⚠️ **特点：**
    - 只有一个参数：平均频率 $\lambda$
        
    - 适用于罕见事件
        
    - 可作为二项分布的极限：$n \to \infty, p \to 0，np = \lambda$
        
- 🚫 **缺点 / 局限：**
    
    - 不能处理“事件之间相关”或“集群”情况
        
    - 不适合建模事件强度，仅次数

### 常见连续分布

#### **📌 均匀分布** 
记作：$U(a,b)$


$$f(x) = \frac{1}{b - a}, \quad x \in [a, b]$$

  

每个值的概率密度一样高。
$$E(X) = \frac{a+b}{2}, \quad D(X) = \frac{(b - a)^2}{12}$$

- 📌 **应用：** 所有结果等可能出现（如：随机生成数）
    
- ⚠️ **特点：**
    
    - 密度是一个常数（水平线）
        
    - 分布函数是线性增长
        
    
- 🚫 **缺点：**
    - 实际上很少有自然现象符合均匀分布
	
### **📌 正态分布** 
记作：$N(\mu, \sigma^2)$，公式

$$f(x) = \frac{1}{\sqrt{2\pi}\sigma} e^{- \frac{(x - \mu)^2}{2\sigma^2}}$$

  

钟形曲线，最重要的分布（自然界大量现象近似服从）

$$E(X) = \mu, \quad D(X) = \sigma^2$$

- 📌 **应用：** 大量自然、社会现象（身高、考试分数等）
    
- ⚠️ **特点：**
    - 对称性：以均值对称
    - 集中性：约 68.3% 落在均值 ±1σ 区间
    - 可叠加：多个独立正态变量加和仍为正态
    
- 🚫 **缺点：**
    - 无界：理论上变量可为负（如身高不合理）
    - 容易误用：很多数据并不正态，但被错误套用
	
### **📌 指数分布** 
记作： $Exp(\lambda)$, 公式：

$$f(x) = \lambda e^{-\lambda x}, \quad x \ge 0$$

  

- **应用：** 表示等待时间、寿命等。$$E(X) = \frac{1}{\lambda}, \quad D(X) = \frac{1}{\lambda^2}$$
    
- ⚠️ **特点：**
    
    - 记忆性：$P(X > s + t \mid X > s) = P(X > t)$
        
    - 密度在 x=0 处最高，之后指数下降

### 多维随机变量

#### **📘 联合分布**

- 两个随机变量 X, Y 取值的组合情况：
		
	- 离散：用联合分布列表示 $P(X = x_i, Y = y_j)$
	    
	- 连续：用联合概率密度函数 f(x, y)
	    
-  ⚠️ **联合分布** 能捕捉变量之间的相关性
#### **📘 边缘分布**

从联合分布中“求出”单个变量的分布：

- 离散：$$P(X = x_i) = \sum_j P(X = x_i, Y = y_j)$$
    
- 连续：   $$f_X(x) = \int_{-\infty}^{\infty} f(x, y)\,dy$$
#### **📘 条件分布**

在知道一个变量取某个值的情况下，另一个变量的分布。  
⚠️ **条件分布** 是理解“事件已知”的概率工具，核心思想和贝叶斯方法一致  