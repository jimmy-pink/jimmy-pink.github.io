{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyM1+bks4FJT4VHacIoxPb0V"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. 问题分析\n",
    "\n",
    "Fashion Mnist 对 28*28 服装类图片标注(贴分类标签)，训练这个数据集可进行服装类型预测，这是一个典型的有监督学习案例。\n",
    "\n",
    "1. 确定训练类型 ： e.g. 识别时装类型\n",
    "2. 收集训练数据集： e.g.  [_Fashion mnist_](https://github.com/zalandoresearch/fashion-mnist)\n",
    "3. 对数据进行标注： e.g. 为每张图片标注 服装类型标签\n",
    "4. 训练：\n",
    "5. 评估：把测试集丢进去，检查识别是否准确\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:30:41.307864Z",
     "start_time": "2025-04-18T02:30:41.304637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. 数据加载与分析\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:30:13.933812Z",
     "start_time": "2025-04-18T02:30:13.890457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ┌───────────────┐\n",
    "# │ 1.数据转换器   │\n",
    "# └───────────────┘\n",
    "#\n",
    "# 1. 定义对图像应用的操作。非常重要！\n",
    "#    - transforms.ToTensor(): 将 PIL.Image 或 NumPy ndarray 转换为 PyTorch Tensor (形状: [C, H, W], 值域: [0.0, 1.0])\n",
    "#    - transforms.Normalize(mean, std): 标准化图像张量。\n",
    "#        - mean (tuple): 各个通道的均值，这里是 (0.5,) 因为是灰度图扩展成3通道。\n",
    "#        - std (tuple): 各个通道的标准差，这里是 (0.5,)。\n",
    "#        PyTorch 会将每个通道的像素值减去对应均值后除以对应标准差。\n",
    "# 注意：如果你一开始不扩展通道，只用 ToTensor()，那么输入张量形状就是 [H, W] 或 [1, H, W]，需要调整模型输入层\n",
    "\n",
    "\n",
    "# 图片尺寸已经是28x28，我们将其转换为[3, 28, 28]的RGB图像\n",
    "# resize可以保证输入图像尺寸一致\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,)) # 对RGB三个通道进行标准化\n",
    "    # 如果你的模型直接接受[H, W]或[1, H, W]张量，可以去掉 ToTensor() 并相应调整模型输入\n",
    "])\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# ┌───────────────┐\n",
    "# │ 下载/加载数据 │\n",
    "# └───────────────┘\n",
    "#\n",
    "# 2. 使用 datasets.FashionMNIST 加载数据\n",
    "#    - root: 数据存储路径\n",
    "#    - train: True 表示下载训练集，False 表示下载测试集\n",
    "#    - download: True 如果需要从互联网下载\n",
    "#    - transform: 应用到每个图像的数据转换器\n",
    "#\n",
    "\n",
    "# 加载训练集 (大约 60,000 个样本)\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "# 加载测试集 (大约 10,000 个样本)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:30:44.131511Z",
     "start_time": "2025-04-18T02:30:44.126382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ┌───────────────┐\n",
    "# │ 创建 DataLoader │\n",
    "# └───────────────┘\n",
    "#\n",
    "# 3. 创建 DataLoader 以方便在训练和推理过程中迭代数据。\n",
    "#    - DataLoader 将Dataset对象包装成可迭代的对象。\n",
    "#    - batch_size: 每个批次包含多少样本。\n",
    "#    - shuffle: 是否在每个epoch开始时打乱训练数据 (通常设置为 True)。\n",
    "#    - num_workers: 使用多少个子进程加载数据 (提高加载速度，根据系统资源设置，0 表示不使用额外进程)。\n",
    "batch_size = 64 # 常见的批量大小\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2) # 测试时不需要打乱"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:30:58.352551Z",
     "start_time": "2025-04-18T02:30:58.333839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ┌───────────────┐\n",
    "# │ 查看数据结构 │\n",
    "# └───────────────┘\n",
    "#\n",
    "# 检查训练集大小和形状\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "example_image, example_label = train_dataset[0]\n",
    "print(f\"Shape of one image tensor: {example_image.shape}\")        # [C, H, W] -> [3, 28, 28]\n",
    "print(f\"Data type of one image tensor: {example_image.dtype}\")   # tensor.float32\n",
    "print(f\"Value range of one image tensor: [{example_image.min().item()}, {example_image.max().item()}]\") # [0.0, 1.0]\n",
    "print(f\"Training labels are initially integers (first 5): {train_dataset.targets[:5]}\")      # [9, 0, 0, 3, 0]\n",
    "print(f\"FashionMNIST class names:\\n{train_dataset.classes}\") # ['T-shirt/top', 'Trouser', ...]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000\n",
      "Shape of one image tensor: torch.Size([1, 28, 28])\n",
      "Data type of one image tensor: torch.float32\n",
      "Value range of one image tensor: [-1.0, 1.0]\n",
      "Training labels are initially integers (first 5): tensor([9, 0, 0, 3, 0])\n",
      "FashionMNIST class names:\n",
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:31:34.089515Z",
     "start_time": "2025-04-18T02:31:31.680779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 检查 DataLoader 在一个 epoch 内会产生多少批次\n",
    "print(f\"\\nNumber of batches in train_loader (one epoch): {len(train_loader)}\")\n",
    "print(f\"Example batch shapes from train_loader:\")\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    if batch_idx == 0: # 只打印第一个批次查看\n",
    "        print(f\"Batch {batch_idx}: images shape: {images.shape}, labels shape: {labels.shape}\") # [B, C, H, W], [B]\n",
    "        print(f\"First image in batch min/max: {images[0].min().item():.2f}, {images[0].max().item():.2f}\")\n",
    "        break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of batches in train_loader (one epoch): 938\n",
      "Example batch shapes from train_loader:\n",
      "Batch 0: images shape: torch.Size([64, 1, 28, 28]), labels shape: torch.Size([64])\n",
      "First image in batch min/max: -1.00, 1.00\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. 数据处理"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:34:02.787277Z",
     "start_time": "2025-04-18T02:34:02.778095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 输出10个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:38:40.183941Z",
     "start_time": "2025-04-18T02:38:35.054925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# 提取特征函数\n",
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, target in dataloader:\n",
    "            output = model(inputs)\n",
    "            features.append(output.numpy())  # 提取的特征\n",
    "            labels.append(target.numpy())\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels\n",
    "\n",
    "# 提取训练集特征\n",
    "train_features, train_labels = extract_features(model, train_loader)\n",
    "test_features, test_labels = extract_features(model, test_loader)\n",
    "print(train_features.shape, train_labels.shape, test_features.shape, test_labels.shape)\n",
    "train_features"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (60000,) (10000, 10) (10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.05564203, -0.14549804,  0.27228755, ..., -0.06906623,\n",
       "         0.20939602, -0.10270488],\n",
       "       [ 0.22178867, -0.27685505,  0.07496391, ...,  0.11466201,\n",
       "         0.18641166, -0.07255948],\n",
       "       [ 0.0788973 , -0.3209244 ,  0.25007313, ...,  0.08427867,\n",
       "         0.27098778, -0.16816346],\n",
       "       ...,\n",
       "       [ 0.24253392, -0.39807236, -0.01522865, ...,  0.09629457,\n",
       "         0.25996435,  0.06932414],\n",
       "       [ 0.10248686, -0.5121202 ,  0.01230931, ...,  0.09224001,\n",
       "        -0.0522152 ,  0.00888842],\n",
       "       [-0.18718103, -0.2970221 ,  0.04109677, ...,  0.033646  ,\n",
       "        -0.15043348, -0.07145831]], shape=(60000, 10), dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. 模型训练"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:39:11.165885Z",
     "start_time": "2025-04-18T02:38:52.772800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 训练随机森林模型\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(train_features, train_labels)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 66.70%\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. 模型评估"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 在测试集上进行预测\n",
    "test_predictions = rf_model.predict(test_features)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f\"Random Forest Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ]
}
